<!DOCTYPE html>
<html lang="en">
  <head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-93464301-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-93464301-1');
    </script>
    <title>3d grid lstm</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="../../launcher-icon-4x.png">
    <link rel="stylesheet" href="../../css/materialize.css">
    <link rel="stylesheet" href="../../css/topnav.css">
    <link rel="stylesheet" href="../../css/post.css">
    <script type="text/javascript" src="../../js/myscript.js"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>

  <body>
    <ul class="topnav">
      <div class="container">
        <li><a href="../../index.html">Home</a></li>
        <li class="right"><a href="../../contact.html">Contact</a></li>
        <li class="right"><a href="../../about.html">About</a></li>
      </div>
    </ul>

    <div class="container">

      <div class="section"><h5><center>3d Grid LSTM</center></h5>
        <p>
          Visualization of the gradients while a 3d Grid LSTM <a href="#references">[1]</a> is learning.
          The colors are red green and blue in the three respective dimensions
          and the size of the balls represent the magnitude of the gradient. For example: a big yellow ball would mean
          the gradients are big in dimensions 1 and 2 (red, green) and not so big in dimension 3 (blue).
          I only feed input in dimension 1 of the input cell (This is why the ball at the top corner of the cube is red) The output cell is in the opposite corner.
        </p>
        <p>
          Note that for the purpose of this visualization, a randomly generated but constant input vector $x$ and target vector $t$ are used.
          The Grid LSTM thus learns the function $t=f(x)$ for a constant $x$ and $t$ which is the simplest possible version of any neural net architecture.
        </p>
        <div class="videowrapper"><iframe src="https://www.youtube.com/embed/zicZXGd_JAI" frameborder="0" allowfullscreen></iframe></div>
        <p>
          The learning scheme is Adam but with a learning rate about 10x higher than
          normal, meaning that parameters are over-adjusted and oscillates to the
          minimum instead of "slowing momentum when getting closer to the minimum".
          I looks natural enough, and I think its because the human body always seem to over compensate
          in response to external input.
        </p>
        <p>
          The below video shows one way real neuronal activity can be visualized.
          Play both videos at the same time to see some similarity.
        </p>
        <div class="videowrapper"><iframe src="https://www.youtube.com/embed/t3TaMU_qXMc?start=16&end=40" frameborder="0" allowfullscreen></iframe></div>
      </div>

      <div class="divider"></div>

      <div class="section"><a name="references"></a>
        <p>
          References: <br>

        [1]. <a href="https://arxiv.org/abs/1507.01526">
          Grid Long Short-Term Memory (Nal Kalchbrenner, Ivo Danihelka, Alex Graves, 2016)</a>
        </p>
      </div>

      <div class="divider"></div>
      <p>
        <center><script>document.write("last modified: " + formatAsUKDate(new Date(document.lastModified)) +"");</script></center>
      </p>
    </div>
  </body>
</html>
